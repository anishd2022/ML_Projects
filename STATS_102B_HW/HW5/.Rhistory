# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- data_std %*% eigenvectors
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(data_std) %*% eigenvectors
# data frame for plot...
data_std_df <- as.data.frame(data_std)
colnames(data_std_df) <- c("attack", "defense")
principal_components_df <- as.data.frame(principal_components)
colnames(principal_components_df) <- c("PC1", "PC2")
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(data_std) %*% eigenvectors
# data frame for plot...
data_std_df <- as.data.frame(data_std)
colnames(data_std_df) <- c("attack", "defense")
principal_components_df <- as.data.frame(principal_components)
colnames(principal_components_df) <- c("PC1", "PC2")
# plot in original axes:
ggplot(data_std_df, aes(x = attack, y = defense)) +
geom_point() +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,1], yend = eigenvectors[2,1]),
arrow = arrow(length = unit(0.3, "cm")), color = "red") +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,2], yend = eigenvectors[2,2]),
arrow = arrow(length = unit(0.3, "cm")), color = "blue") +
ggtitle("Pokémon Data in Original Axes with Loadings") +
xlab("Standardized Attack") + ylab("Standardized Defense")
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(data_std) %*% eigenvectors
# data frame for plot...
data_std_df <- as.data.frame(data_std)
colnames(data_std_df) <- c("attack", "defense")
principal_components_df <- as.data.frame(principal_components)
colnames(principal_components_df) <- c("PC1", "PC2")
# plot in original axes:
ggplot(data_std_df, aes(x = attack, y = defense)) +
geom_point() +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,1], yend = eigenvectors[2,1]),
arrow = arrow(length = unit(0.3, "cm")), color = "red") +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,2], yend = eigenvectors[2,2]),
arrow = arrow(length = unit(0.3, "cm")), color = "blue") +
ggtitle("Pokémon Data in Original Axes with Loadings") +
xlab("Standardized Attack") + ylab("Standardized Defense")
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(data_std) %*% eigenvectors
# data frame for plot...
data_std_df <- as.data.frame(data_std)
colnames(data_std_df) <- c("attack", "defense")
principal_components_df <- as.data.frame(principal_components)
colnames(principal_components_df) <- c("PC1", "PC2")
# plot in original axes:
ggplot(data_std_df, aes(x = attack, y = defense)) +
geom_point(color = 'orange', alpha = 0.4) +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,1], yend = eigenvectors[2,1]),
arrow = arrow(length = unit(0.3, "cm")), color = "red") +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,2], yend = eigenvectors[2,2]),
arrow = arrow(length = unit(0.3, "cm")), color = "blue") +
ggtitle("Pokémon Data in Original Axes with Loadings") +
xlab("Standardized Attack") + ylab("Standardized Defense")
# standardize attack and defense columns
pokemon_data <- pokemon_data %>%
mutate(attack_std = scale(attack),
defense_std = scale(defense))
# extract appropriate columns
data_std <- pokemon_data %>%
select(c(attack_std, defense_std))
# compute covariance matrix
cov_matrix <- cov(data_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(data_std) %*% eigenvectors
# data frame for plot...
data_std_df <- as.data.frame(data_std)
colnames(data_std_df) <- c("attack", "defense")
principal_components_df <- as.data.frame(principal_components)
colnames(principal_components_df) <- c("PC1", "PC2")
# plot in original axes:
ggplot(data_std_df, aes(x = attack, y = defense)) +
geom_point(color = 'orange', alpha = 0.4) +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,1], yend = eigenvectors[2,1]),
arrow = arrow(length = unit(0.3, "cm")), color = "red") +
geom_segment(aes(x = 0, y = 0, xend = eigenvectors[1,2], yend = eigenvectors[2,2]),
arrow = arrow(length = unit(0.3, "cm")), color = "blue") +
ggtitle("Pokémon Data in Original Axes with Loadings") +
xlab("Standardized Attack") + ylab("Standardized Defense")
# plot in principal component axes:
ggplot(principal_components_df, aes(x = PC1, y = PC2)) +
geom_point(color = 'orange', alpha = 0.4) +
geom_segment(aes(x = 0, y = 0, xend = sqrt(eigenvalues[1]), yend = 0),
arrow = arrow(length = unit(0.3, "cm")), color = "red") +
geom_segment(aes(x = 0, y = 0, xend = 0, yend = sqrt(eigenvalues[2])),
arrow = arrow(length = unit(0.3, "cm")), color = "blue") +
ggtitle("Pokémon Data in Principal Component Axes with Loadings") +
xlab("PC1") + ylab("PC2")
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(numeric_columns_std) %*% eigenvectors
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(numeric_columns_std) %*% eigenvectors
# print the result:
head(principal_components[, 1], 6)
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(numeric_columns_std) %*% eigenvectors
# print the result:
head(principal_components[, 1])
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(numeric_columns_std) %*% eigenvectors
# print the result:
head(principal_components[, 1], 6)
# Select the numeric columns from height_m to base_experience
numeric_columns <- pokemon_data %>%
select(height_m:base_experience)
# Standardize the selected columns
numeric_columns_std <- scale(numeric_columns)
# get covariance matrix
cov_matrix <- cov(numeric_columns_std)
# get eigenvalues and eigenvectors
eigen_result <- eigen(cov_matrix)
eigenvalues <- eigen_result$values
eigenvectors <- eigen_result$vectors
# project data onto eigenvectors to obtain principal components
principal_components <- as.matrix(numeric_columns_std) %*% eigenvectors
# print the result:
head(principal_components[, 1])
View(pokemon_data)
knitr::opts_chunk$set(echo = TRUE)
# read in pokemon data
pokemon_data <- read_csv("pokemon.csv", show_col_types = FALSE)
# include necessary libraries:
library(ggplot2)
library(tidyverse)
# read in pokemon data
pokemon_data <- read_csv("pokemon.csv", show_col_types = FALSE)
# Find the index of the first and last column to standardize
start_col <- which(names(pokemon_data) == "height_m")
end_col <- which(names(pokemon_data) == "base_experience")
# Standardize the columns from height_m to base_experience
pokemon_data[, start_col:end_col] <- lapply(pokemon_data[, start_col:end_col], scale)
# subset pokemon data by generation
gen1 <- pokemon_data %>% filter(generation == 1)
gen2 <- pokemon_data %>% filter(generation == 2)
# show first 6 rows of gen1:
head(gen1)
# show first 6 rows of gen2:
head(gen2)
# trainx: a data frame of the training observations
# trainy: a vector of the training labels
# testx: a data frame of the testing (new) observations
# k: the number of neighbors
# output: a vector of the predicted labels corresponding to the new observations
# first write helper function to get Euclidean Distance given a vector x and y of equal length:
GetEuclidianDistance <- function(x, y) {
result <- sqrt(sum((x - y)^2))
# return the result
result
}
# knn function implementation:
knn <- function(trainx, trainy, testx, k) {
# set result to be empty vector:
result <- c()
# for each new testx case:
for (i in 1:nrow(testx)) {
# create empty distances vector
distances <- c()
# compute the distance between the test case and each training observation:
for (j in 1:nrow(trainx)) {
distance <- GetEuclidianDistance(testx[i, ], trainx[j, ])
# append distance to distance vector
distances <- append(distances, distance)
}
# create a data frame of distances and indexes, then arrange by increasing distance
indexes <- c(1:length(trainy))
point_data_frame <- data.frame(distances = distances, indexes = indexes) %>% arrange(distances)
# choose the k nearest neighbors:
interested_indexes <- point_data_frame$indexes[1:k]
# get the extracted y labels:
nearest_labels <- trainy[interested_indexes]
freq_table <- table(nearest_labels)
label <- names(freq_table[which.max(freq_table)])
# append label to the result
result <- append(result, label)
}
# convert result to logical
result <- as.logical(result)
# return the result
result
}
trainx <- gen1[, c("total_points", "hp")]
testx <- gen2[, c("total_points", "hp")]
trainy <- gen1$is_legendary
knn(trainx, trainy, testx, 5)
# compute the misclassification rate...
# creating a helper function:
GetMisclassificationRate <- function(predicted_labels, actual_labels) {
correct <- 0
wrong <- 0
# for each label, check if it is correctly classified:
for (i in 1:length(actual_labels)) {
if (predicted_labels[i] == actual_labels[i]) {
correct <- correct + 1
} else {
wrong <- wrong + 1
}
}
result <- wrong / (wrong + correct)
# return the result
result
}
pred_labels <- knn(trainx, trainy, testx, 5)
true_labels <- gen2$is_legendary
misclassification_rate <- GetMisclassificationRate(pred_labels, true_labels)
misclassification_rate
# set seed for reproducibility:
set.seed(1313)
# use 6 fold cross validation:
k_values <- c(3, 7, 11, 21, 51)
# creating a k fold cross validation function
k_fold_cv <- function(data, k, K = 6) {
# find number of observations:
n <- nrow(data)
# randomly shuffle the indices:
indices <- sample(1:n)
# set each testing set to have n/K data points:
fold_size <- ceiling(n / K)
# set an empty vector of length K to be filled with misclassification values for later:
misclassification_values <- numeric(K)
# for each fold...
for (i in 1:K) {
start_index <- (i - 1) * fold_size + 1
end_index <- min(i * fold_size, n)
test_indices <- indices[start_index:end_index]
# set train indices to be everything except what you are testing on
train_indices <- indices[-(start_index:end_index)]
# train the model on the training set:
trainx <- data[train_indices, c("total_points", "hp")]
trainy <- data[train_indices, ]$is_legendary
testx <- data[test_indices, c("total_points", "hp")]
pred_labels <- knn(trainx, trainy, testx, k)
true_labels <- data[test_indices, ]$is_legendary
# calculate misclassification rate
rate <- GetMisclassificationRate(pred_labels, true_labels)
# append rate to result vector
misclassification_values <- append(misclassification_values, rate)
}
# return the result
mean(misclassification_values)
}
# run k-fold cross validation for all k values:
cv_results <- sapply(k_values, function(k) k_fold_cv(gen1, k, K = 6))
results_df <- data.frame(k = k_values, misclassification_rate = cv_results)
results_df
# Prepare training and testing data
trainx <- gen1[, c("total_points", "hp")]
trainy <- gen1$is_legendary
testx <- gen2[, c("total_points", "hp")]
testy <- gen2$is_legendary
# Predict using k-NN with k = 3
pred_labels <- knn(trainx, trainy, testx, 3)
# Calculate the misclassification rate
misclassification_rate <- GetMisclassificationRate(pred_labels, testy)
cat("Misclassification Rate:", misclassification_rate, "\n")
# Create the confusion matrix
confusion_matrix <- table(Predicted = pred_labels, Actual = testy)
# Display the confusion matrix
confusion_matrix
ggplot(data = pokemon_data, aes(x = speed, y = base_experience)) +
geom_jitter()
# implementing k-means algorithm...
# trainx is the n observations
# k is the number of clusters
k_means <- function(trainx, k, distance = "euclidean") {
# Define the distance function based on the specified distance metric
distance_function <- switch(distance,
euclidean = function(a, b) sqrt(sum((a - b)^2)),
manhattan = function(a, b) sum(abs(a - b)),
mahalanobis = function(a, b)
sqrt(as.matrix(a - b) %*% cov_inv %*% as.matrix(t(a - b))),
custom = function(a, b)
sqrt(as.matrix(a - b) %*% Q %*% as.matrix(t(a - b))),
stop("Unsupported distance metric"))
if (distance == "mahalanobis") {
# Compute the inverse of the covariance matrix
cov_mat <- cov(trainx)
cov_inv <- solve(cov_mat)  # Inverse of the covariance matrix
}
if (distance == "custom") {
Q <- matrix(c(1, -2, -2, 10), nrow = 2, ncol = 2, byrow = TRUE)
}
# Find the number of observations
n <- nrow(trainx)
# Randomly assign a number 1 to k for each of the n observations
cluster_assignments <- sample(1:k, n, replace = TRUE)
keep_going <- TRUE
while (keep_going) {
keep_going <- FALSE
centroids <- matrix(0, nrow = k, ncol = ncol(trainx))
# Compute the centroids for each cluster
for (i in 1:k) {
k_data <- trainx[which(cluster_assignments == i), ]
if (nrow(k_data) > 0) {
centroids[i, ] <- colMeans(k_data)
}
}
new_assignments <- cluster_assignments
# Reassign points to the nearest centroid
for (i in 1:n) {
distances <- apply(centroids, 1, function(centroid) distance_function(trainx[i, ], centroid))
new_assignments[i] <- which.min(distances)
}
# Check if there are any changes in assignments
if (!all(new_assignments == cluster_assignments)) {
keep_going <- TRUE
}
cluster_assignments <- new_assignments
}
list(assignments = cluster_assignments, centroids = centroids)
}
# run the k-means algorithm with euclidean distance...
trainx <- pokemon_data[, c("speed", "base_experience")]
k_means_result <- k_means(trainx, 3, "euclidean")
trainx$cluster <- as.factor(k_means_result$assignments)
# Convert centroids to a data frame with appropriate column names
centroids_df <- data.frame(k_means_result$centroids)
colnames(centroids_df) <- colnames(trainx)[1:2]
centroids_df$cluster <- as.factor(1:nrow(centroids_df))
# Plotting
ggplot(trainx, aes(x = speed, y = base_experience, color = cluster)) +
geom_point() +
geom_point(data = centroids_df, aes(x = speed, y = base_experience, color = cluster),
shape = 17, size = 8) +
labs(color = "Cluster") +
theme_minimal() +
ggtitle("K-Means Clustering of Pokémon Data (Euclidian Distance)") +
xlab("Speed") +
ylab("Base Experience")
trainx <- pokemon_data[, c("speed", "base_experience")]
k_means_result <- k_means(trainx, 3, "manhattan")
trainx$cluster <- as.factor(k_means_result$assignments)
# Convert centroids to a data frame with appropriate column names
centroids_df <- data.frame(k_means_result$centroids)
colnames(centroids_df) <- colnames(trainx)[1:2]
centroids_df$cluster <- as.factor(1:nrow(centroids_df))
# Plotting
ggplot(trainx, aes(x = speed, y = base_experience, color = cluster)) +
geom_point() +
geom_point(data = centroids_df, aes(x = speed, y = base_experience, color = cluster),
shape = 17, size = 8) +
labs(color = "Cluster") +
theme_minimal() +
ggtitle("K-Means Clustering of Pokémon Data (Manhattan Distance)") +
xlab("Speed") +
ylab("Base Experience")
trainx <- pokemon_data[, c("speed", "base_experience")]
k_means_result <- k_means(trainx, 3, "mahalanobis")
trainx$cluster <- as.factor(k_means_result$assignments)
# Convert centroids to a data frame with appropriate column names
centroids_df <- data.frame(k_means_result$centroids)
colnames(centroids_df) <- colnames(trainx)[1:2]
centroids_df$cluster <- as.factor(1:nrow(centroids_df))
# Plotting
ggplot(trainx, aes(x = speed, y = base_experience, color = cluster)) +
geom_point() +
geom_point(data = centroids_df, aes(x = speed, y = base_experience, color = cluster),
shape = 17, size = 8) +
labs(color = "Cluster") +
theme_minimal() +
ggtitle("K-Means Clustering of Pokémon Data (Mahalanobis Distance)") +
xlab("Speed") +
ylab("Base Experience")
trainx <- pokemon_data[, c("speed", "base_experience")]
k_means_result <- k_means(trainx, 3, "custom")
trainx$cluster <- as.factor(k_means_result$assignments)
# Convert centroids to a data frame with appropriate column names
centroids_df <- data.frame(k_means_result$centroids)
colnames(centroids_df) <- colnames(trainx)[1:2]
centroids_df$cluster <- as.factor(1:nrow(centroids_df))
# Plotting
ggplot(trainx, aes(x = speed, y = base_experience, color = cluster)) +
geom_point() +
geom_point(data = centroids_df, aes(x = speed, y = base_experience, color = cluster),
shape = 17, size = 8) +
labs(color = "Cluster") +
theme_minimal() +
ggtitle("K-Means Clustering of Pokémon Data (Custom Distance)") +
xlab("Speed") +
ylab("Base Experience")
